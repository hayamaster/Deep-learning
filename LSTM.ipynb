{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hayamaster/Deep-learning/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKuaf5dXV0l-",
        "outputId": "2efe64f3-8a40-4871-90b5-becd47bc07fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jK1l83CiWGIr",
        "outputId": "7d78abd0-1326-4cdb-f764-9dea7eba2931"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch0\n",
            "tensor(3.1458, grad_fn=<NllLossBackward0>)\n",
            "epoch10\n",
            "tensor(3.1612, grad_fn=<NllLossBackward0>)\n",
            "epoch20\n",
            "tensor(3.0216, grad_fn=<NllLossBackward0>)\n",
            "epoch30\n",
            "tensor(2.9391, grad_fn=<NllLossBackward0>)\n",
            "epoch40\n",
            "tensor(3.0318, grad_fn=<NllLossBackward0>)\n",
            "epoch50\n",
            "tensor(2.9854, grad_fn=<NllLossBackward0>)\n",
            "epoch60\n",
            "tensor(2.9735, grad_fn=<NllLossBackward0>)\n",
            "epoch70\n",
            "tensor(3.0189, grad_fn=<NllLossBackward0>)\n",
            "epoch80\n",
            "tensor(2.9786, grad_fn=<NllLossBackward0>)\n",
            "epoch90\n",
            "tensor(3.0430, grad_fn=<NllLossBackward0>)\n",
            "epoch100\n",
            "tensor(3.0217, grad_fn=<NllLossBackward0>)\n",
            "epoch110\n",
            "tensor(3.0054, grad_fn=<NllLossBackward0>)\n",
            "epoch120\n",
            "tensor(2.9514, grad_fn=<NllLossBackward0>)\n",
            "epoch130\n",
            "tensor(2.9022, grad_fn=<NllLossBackward0>)\n",
            "epoch140\n",
            "tensor(2.8445, grad_fn=<NllLossBackward0>)\n",
            "epoch150\n",
            "tensor(2.7951, grad_fn=<NllLossBackward0>)\n",
            "epoch160\n",
            "tensor(2.7774, grad_fn=<NllLossBackward0>)\n",
            "epoch170\n",
            "tensor(2.7594, grad_fn=<NllLossBackward0>)\n",
            "epoch180\n",
            "tensor(2.7618, grad_fn=<NllLossBackward0>)\n",
            "epoch190\n",
            "tensor(2.7401, grad_fn=<NllLossBackward0>)\n",
            "epoch200\n",
            "tensor(2.7157, grad_fn=<NllLossBackward0>)\n",
            "epoch210\n",
            "tensor(2.7493, grad_fn=<NllLossBackward0>)\n",
            "epoch220\n",
            "tensor(2.7354, grad_fn=<NllLossBackward0>)\n",
            "epoch230\n",
            "tensor(2.7091, grad_fn=<NllLossBackward0>)\n",
            "epoch240\n",
            "tensor(2.7323, grad_fn=<NllLossBackward0>)\n",
            "epoch250\n",
            "tensor(2.6736, grad_fn=<NllLossBackward0>)\n",
            "epoch260\n",
            "tensor(2.7200, grad_fn=<NllLossBackward0>)\n",
            "epoch270\n",
            "tensor(2.6902, grad_fn=<NllLossBackward0>)\n",
            "epoch280\n",
            "tensor(2.6614, grad_fn=<NllLossBackward0>)\n",
            "epoch290\n",
            "tensor(2.6973, grad_fn=<NllLossBackward0>)\n",
            "epoch300\n",
            "tensor(2.6605, grad_fn=<NllLossBackward0>)\n",
            "epoch310\n",
            "tensor(2.6479, grad_fn=<NllLossBackward0>)\n",
            "epoch320\n",
            "tensor(2.6623, grad_fn=<NllLossBackward0>)\n",
            "epoch330\n",
            "tensor(2.6613, grad_fn=<NllLossBackward0>)\n",
            "epoch340\n",
            "tensor(2.6928, grad_fn=<NllLossBackward0>)\n",
            "epoch350\n",
            "tensor(2.6674, grad_fn=<NllLossBackward0>)\n",
            "epoch360\n",
            "tensor(2.6542, grad_fn=<NllLossBackward0>)\n",
            "epoch370\n",
            "tensor(2.6471, grad_fn=<NllLossBackward0>)\n",
            "epoch380\n",
            "tensor(2.6675, grad_fn=<NllLossBackward0>)\n",
            "epoch390\n",
            "tensor(2.7096, grad_fn=<NllLossBackward0>)\n",
            "epoch400\n",
            "tensor(2.6640, grad_fn=<NllLossBackward0>)\n",
            "epoch410\n",
            "tensor(2.7151, grad_fn=<NllLossBackward0>)\n",
            "epoch420\n",
            "tensor(2.6600, grad_fn=<NllLossBackward0>)\n",
            "epoch430\n",
            "tensor(2.6619, grad_fn=<NllLossBackward0>)\n",
            "epoch440\n",
            "tensor(2.6545, grad_fn=<NllLossBackward0>)\n",
            "epoch450\n",
            "tensor(2.6480, grad_fn=<NllLossBackward0>)\n",
            "epoch460\n",
            "tensor(2.6696, grad_fn=<NllLossBackward0>)\n",
            "epoch470\n",
            "tensor(2.6414, grad_fn=<NllLossBackward0>)\n",
            "epoch480\n",
            "tensor(2.6635, grad_fn=<NllLossBackward0>)\n",
            "epoch490\n",
            "tensor(2.6475, grad_fn=<NllLossBackward0>)\n",
            "epoch500\n",
            "tensor(2.6462, grad_fn=<NllLossBackward0>)\n",
            "epoch510\n",
            "tensor(2.6605, grad_fn=<NllLossBackward0>)\n",
            "epoch520\n",
            "tensor(2.6501, grad_fn=<NllLossBackward0>)\n",
            "epoch530\n",
            "tensor(2.6548, grad_fn=<NllLossBackward0>)\n",
            "epoch540\n",
            "tensor(2.6605, grad_fn=<NllLossBackward0>)\n",
            "epoch550\n",
            "tensor(2.6812, grad_fn=<NllLossBackward0>)\n",
            "epoch560\n",
            "tensor(2.6421, grad_fn=<NllLossBackward0>)\n",
            "epoch570\n",
            "tensor(2.6907, grad_fn=<NllLossBackward0>)\n",
            "epoch580\n",
            "tensor(2.6475, grad_fn=<NllLossBackward0>)\n",
            "epoch590\n",
            "tensor(2.6499, grad_fn=<NllLossBackward0>)\n",
            "epoch600\n",
            "tensor(2.6491, grad_fn=<NllLossBackward0>)\n",
            "epoch610\n",
            "tensor(2.6916, grad_fn=<NllLossBackward0>)\n",
            "epoch620\n",
            "tensor(2.6679, grad_fn=<NllLossBackward0>)\n",
            "epoch630\n",
            "tensor(2.6452, grad_fn=<NllLossBackward0>)\n",
            "epoch640\n",
            "tensor(2.6439, grad_fn=<NllLossBackward0>)\n",
            "epoch650\n",
            "tensor(2.6432, grad_fn=<NllLossBackward0>)\n",
            "epoch660\n",
            "tensor(2.6393, grad_fn=<NllLossBackward0>)\n",
            "epoch670\n",
            "tensor(2.6373, grad_fn=<NllLossBackward0>)\n",
            "epoch680\n",
            "tensor(2.6180, grad_fn=<NllLossBackward0>)\n",
            "epoch690\n",
            "tensor(2.6536, grad_fn=<NllLossBackward0>)\n",
            "epoch700\n",
            "tensor(2.6516, grad_fn=<NllLossBackward0>)\n",
            "epoch710\n",
            "tensor(2.6535, grad_fn=<NllLossBackward0>)\n",
            "epoch720\n",
            "tensor(2.6630, grad_fn=<NllLossBackward0>)\n",
            "epoch730\n",
            "tensor(2.6293, grad_fn=<NllLossBackward0>)\n",
            "epoch740\n",
            "tensor(2.6358, grad_fn=<NllLossBackward0>)\n",
            "epoch750\n",
            "tensor(2.6556, grad_fn=<NllLossBackward0>)\n",
            "epoch760\n",
            "tensor(2.6467, grad_fn=<NllLossBackward0>)\n",
            "epoch770\n",
            "tensor(2.6414, grad_fn=<NllLossBackward0>)\n",
            "epoch780\n",
            "tensor(2.6635, grad_fn=<NllLossBackward0>)\n",
            "epoch790\n",
            "tensor(2.6390, grad_fn=<NllLossBackward0>)\n",
            "epoch800\n",
            "tensor(2.6493, grad_fn=<NllLossBackward0>)\n",
            "epoch810\n",
            "tensor(2.6522, grad_fn=<NllLossBackward0>)\n",
            "epoch820\n",
            "tensor(2.6435, grad_fn=<NllLossBackward0>)\n",
            "epoch830\n",
            "tensor(2.6475, grad_fn=<NllLossBackward0>)\n",
            "epoch840\n",
            "tensor(2.6425, grad_fn=<NllLossBackward0>)\n",
            "epoch850\n",
            "tensor(2.6502, grad_fn=<NllLossBackward0>)\n",
            "epoch860\n",
            "tensor(2.6390, grad_fn=<NllLossBackward0>)\n",
            "epoch870\n",
            "tensor(2.6490, grad_fn=<NllLossBackward0>)\n",
            "epoch880\n",
            "tensor(2.6521, grad_fn=<NllLossBackward0>)\n",
            "epoch890\n",
            "tensor(2.6379, grad_fn=<NllLossBackward0>)\n",
            "1 GT:basic OUT:bntnc\n",
            "2 GT:beach OUT:bteci\n",
            "3 GT:below OUT:btter\n",
            "4 GT:black OUT:blece\n",
            "5 GT:brown OUT:beaii\n",
            "6 GT:carry OUT:cicea\n",
            "7 GT:cream OUT:ceeee\n",
            "8 GT:drink OUT:deane\n",
            "9 GT:error OUT:etaei\n",
            "10 GT:event OUT:eeaee\n",
            "11 GT:exist OUT:eeree\n",
            "12 GT:first OUT:fonoc\n",
            "13 GT:funny OUT:feeea\n",
            "14 GT:guess OUT:gecet\n",
            "15 GT:human OUT:heeae\n",
            "16 GT:image OUT:iceer\n",
            "17 GT:large OUT:letei\n",
            "18 GT:magic OUT:mitin\n",
            "19 GT:mouse OUT:mircn\n",
            "20 GT:night OUT:necia\n",
            "21 GT:noise OUT:neucn\n",
            "22 GT:ocean OUT:oueen\n",
            "23 GT:often OUT:oieie\n",
            "24 GT:order OUT:oiain\n",
            "25 GT:peace OUT:poene\n",
            "26 GT:phone OUT:peeia\n",
            "27 GT:print OUT:paeta\n",
            "28 GT:quiet OUT:qicee\n",
            "29 GT:reach OUT:ralee\n",
            "30 GT:rough OUT:reiei\n",
            "31 GT:round OUT:reite\n",
            "32 GT:scene OUT:snele\n",
            "33 GT:score OUT:seiie\n",
            "34 GT:sense OUT:seeen\n",
            "35 GT:skill OUT:screl\n",
            "36 GT:sleep OUT:sneen\n",
            "37 GT:small OUT:snote\n",
            "38 GT:storm OUT:steia\n",
            "39 GT:table OUT:teeel\n",
            "40 GT:think OUT:tiece\n",
            "41 GT:touch OUT:tiici\n",
            "42 GT:twice OUT:teece\n",
            "43 GT:until OUT:ueeec\n",
            "44 GT:upset OUT:utent\n",
            "45 GT:voice OUT:verti\n",
            "46 GT:waste OUT:weeee\n",
            "47 GT:watch OUT:witie\n",
            "48 GT:white OUT:weele\n",
            "49 GT:woman OUT:weiec\n",
            "50 GT:young OUT:yorte\n",
            "final text accuracy 10/50 (0.2000)\n",
            "whole text accuracy 28/200 (0.1400)\n"
          ]
        }
      ],
      "source": [
        "# \n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "chars = \"abcdefghijklmnopqrstuvwxyz\"\n",
        "char_list = [i for i in chars]\n",
        "n_letters = len(char_list)\n",
        "\n",
        "n_layers = 3\n",
        "\n",
        "five_words = ['basic','beach','below','black','brown','carry','cream','drink','error','event','exist','first','funny','guess','human','image','large','magic','mouse','night','noise','ocean','often','order','peace','phone','print','quiet','reach','rough','round','scene','score','sense','skill','sleep','small','storm','table','think','touch','twice','until','upset','voice','waste','watch','white','woman','young']\n",
        "n_five_words = len(five_words)\n",
        "\n",
        "sequence_length = 4\n",
        "\n",
        "def word_to_onehot(string):\n",
        "    one_hot = np.array([]).reshape(0,n_letters)\n",
        "    for i in string:\n",
        "        idx = char_list.index(i)\n",
        "        zero = np.zeros(shape=n_letters, dtype=int)\n",
        "        zero[idx] = 1\n",
        "        one_hot = np.vstack([one_hot, zero])\n",
        "    return one_hot \n",
        "\n",
        "def onehot_to_word(onehot_1):\n",
        "    onehot = torch.Tensor.numpy(onehot_1)\n",
        "    return char_list[onehot.argmax()]\n",
        "\n",
        "\n",
        "class myLSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layer):\n",
        "      super(myLSTM,  self).__init__()\n",
        "      self.input_size = input_size\n",
        "      self.hidden_size = hidden_size\n",
        "      self.num_layer = num_layer\n",
        "      self.num_directions = 1\n",
        "      self.lstm = nn.LSTM(input_size = input_size,hidden_size=hidden_size, num_layers=num_layer, batch_first=True)\n",
        "\n",
        "  def forward(self, x, hidden):\n",
        "      #out, hidden = self.lstm(x, hidden)\n",
        "      h_0 = torch.randn(self.num_directions * self.num_layer, 4, self.hidden_size)\n",
        "      c_0 = torch.randn(self.num_directions * self.num_layer, 4, self.hidden_size)\n",
        "      out, hidden = self.lstm(x, (h_0,c_0))\n",
        "      return out, hidden\n",
        "\n",
        "  def init_hidden(self):\n",
        "      return torch.zeros(self.num_layer, 1, self.hidden_size)\n",
        "\n",
        "\n",
        "def main():\n",
        "    n_hidden = 28\n",
        "    lr = 0.001\n",
        "    epochs = 900\n",
        "\n",
        "    model = myLSTM(n_letters, n_hidden, n_layers)\n",
        "\n",
        "    loss_func = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 300, gamma=0.1)\n",
        "\n",
        "    for i in range(epochs):\n",
        "        total_loss = 0\n",
        "        for j in range(n_five_words):\n",
        "            hidden = model.init_hidden()\n",
        "            string = five_words[j]\n",
        "            one_hot = torch.from_numpy(word_to_onehot(string)).type_as(torch.FloatTensor())\n",
        "            model.zero_grad()\n",
        "            hidden = model.init_hidden()\n",
        "            input = one_hot[0:-1]\n",
        "            input = torch.unsqueeze(input, 1)\n",
        "            target = np.argmax(one_hot[1:], axis=1)\n",
        "\n",
        "            output, hidden  = model(input, hidden)\n",
        "            loss = loss_func(output.squeeze(1), target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "        if i%10 == 0:\n",
        "             print('epoch%d'%i)\n",
        "             print(loss)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    torch.save(model.state_dict(), 'trained.pth')\n",
        "    model.load_state_dict(torch.load('trained.pth'))\n",
        "\n",
        "\t\n",
        "    with torch.no_grad():\n",
        "        total = 0\n",
        "        positive = 0\n",
        "        total_text = 0\n",
        "        positive_text = 0\n",
        "        for i in range(n_five_words):\n",
        "            string = five_words[i]\n",
        "            one_hot = torch.from_numpy(word_to_onehot(string)).type_as(torch.FloatTensor())\n",
        "            hidden = model.init_hidden()\n",
        "\n",
        "            input = one_hot[0:-1]\n",
        "            input = torch.unsqueeze(input, 1)\n",
        "            target = np.argmax(one_hot[1:], axis=1)\n",
        "            output, hidden = model(input, hidden)\n",
        "            output = output.squeeze()\n",
        "\n",
        "            output_string = string[0]\n",
        "            for j in range(output.size()[0]):\n",
        "                output_string += onehot_to_word(output[j].data)\n",
        "                total_text += 1\n",
        "                if string[j+1] == output_string[-1]:\n",
        "                    positive_text += 1\n",
        "\n",
        "            total += 1\n",
        "            if string[-1] == output_string[-1]:\n",
        "                positive += 1\n",
        "\n",
        "            print('%d GT:%s OUT:%s'%(i+1, string, output_string))\n",
        "\n",
        "        print('final text accuracy %d/%d (%.4f)'%(positive, total, positive/total))\n",
        "        print('whole text accuracy %d/%d (%.4f)' % (positive_text, total_text, positive_text / total_text))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1qmOkId__JK",
        "outputId": "0c41b67e-7cf5-44d7-e5e1-45d2e41b42ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch0\n",
            "tensor(3.4526, grad_fn=<NllLossBackward0>)\n",
            "epoch10\n",
            "tensor(3.0011, grad_fn=<NllLossBackward0>)\n",
            "epoch20\n",
            "tensor(2.7512, grad_fn=<NllLossBackward0>)\n",
            "epoch30\n",
            "tensor(2.5794, grad_fn=<NllLossBackward0>)\n",
            "epoch40\n",
            "tensor(2.4381, grad_fn=<NllLossBackward0>)\n",
            "epoch50\n",
            "tensor(2.3203, grad_fn=<NllLossBackward0>)\n",
            "epoch60\n",
            "tensor(2.2393, grad_fn=<NllLossBackward0>)\n",
            "epoch70\n",
            "tensor(2.1856, grad_fn=<NllLossBackward0>)\n",
            "epoch80\n",
            "tensor(2.1658, grad_fn=<NllLossBackward0>)\n",
            "epoch90\n",
            "tensor(2.1444, grad_fn=<NllLossBackward0>)\n",
            "epoch100\n",
            "tensor(2.1141, grad_fn=<NllLossBackward0>)\n",
            "epoch110\n",
            "tensor(2.0853, grad_fn=<NllLossBackward0>)\n",
            "epoch120\n",
            "tensor(2.0785, grad_fn=<NllLossBackward0>)\n",
            "epoch130\n",
            "tensor(2.0742, grad_fn=<NllLossBackward0>)\n",
            "epoch140\n",
            "tensor(2.0721, grad_fn=<NllLossBackward0>)\n",
            "epoch150\n",
            "tensor(2.0733, grad_fn=<NllLossBackward0>)\n",
            "epoch160\n",
            "tensor(2.0725, grad_fn=<NllLossBackward0>)\n",
            "epoch170\n",
            "tensor(2.0697, grad_fn=<NllLossBackward0>)\n",
            "epoch180\n",
            "tensor(2.0694, grad_fn=<NllLossBackward0>)\n",
            "epoch190\n",
            "tensor(2.0689, grad_fn=<NllLossBackward0>)\n",
            "epoch200\n",
            "tensor(2.0685, grad_fn=<NllLossBackward0>)\n",
            "epoch210\n",
            "tensor(2.0682, grad_fn=<NllLossBackward0>)\n",
            "epoch220\n",
            "tensor(2.0680, grad_fn=<NllLossBackward0>)\n",
            "epoch230\n",
            "tensor(2.0678, grad_fn=<NllLossBackward0>)\n",
            "epoch240\n",
            "tensor(2.0677, grad_fn=<NllLossBackward0>)\n",
            "epoch250\n",
            "tensor(2.0675, grad_fn=<NllLossBackward0>)\n",
            "epoch260\n",
            "tensor(2.0674, grad_fn=<NllLossBackward0>)\n",
            "epoch270\n",
            "tensor(2.0674, grad_fn=<NllLossBackward0>)\n",
            "epoch280\n",
            "tensor(2.0673, grad_fn=<NllLossBackward0>)\n",
            "epoch290\n",
            "tensor(2.0673, grad_fn=<NllLossBackward0>)\n",
            "epoch300\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch310\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch320\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch330\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch340\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch350\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch360\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch370\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch380\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch390\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch400\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch410\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch420\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch430\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch440\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch450\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch460\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch470\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch480\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch490\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch500\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch510\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch520\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch530\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch540\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch550\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch560\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch570\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch580\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch590\n",
            "tensor(2.0672, grad_fn=<NllLossBackward0>)\n",
            "epoch600\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch610\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch620\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch630\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch640\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch650\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch660\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch670\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch680\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch690\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch700\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch710\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch720\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch730\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch740\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch750\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch760\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch770\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch780\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch790\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch800\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch810\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch820\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch830\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch840\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch850\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch860\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch870\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch880\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "epoch890\n",
            "tensor(2.0671, grad_fn=<NllLossBackward0>)\n",
            "1 GT:basic OUT:brlcc\n",
            "2 GT:beach OUT:brach\n",
            "3 GT:below OUT:braow\n",
            "4 GT:black OUT:brack\n",
            "5 GT:brown OUT:brown\n",
            "6 GT:carry OUT:carry\n",
            "7 GT:cream OUT:caeam\n",
            "8 GT:drink OUT:drink\n",
            "9 GT:error OUT:eveor\n",
            "10 GT:event OUT:event\n",
            "11 GT:exist OUT:evist\n",
            "12 GT:first OUT:furst\n",
            "13 GT:funny OUT:funsy\n",
            "14 GT:guess OUT:guess\n",
            "15 GT:human OUT:human\n",
            "16 GT:image OUT:image\n",
            "17 GT:large OUT:large\n",
            "18 GT:magic OUT:magic\n",
            "19 GT:mouse OUT:mause\n",
            "20 GT:night OUT:niiht\n",
            "21 GT:noise OUT:niise\n",
            "22 GT:ocean OUT:ouean\n",
            "23 GT:often OUT:outen\n",
            "24 GT:order OUT:oueer\n",
            "25 GT:peace OUT:prace\n",
            "26 GT:phone OUT:prone\n",
            "27 GT:print OUT:pront\n",
            "28 GT:quiet OUT:quiet\n",
            "29 GT:reach OUT:reach\n",
            "30 GT:rough OUT:reunh\n",
            "31 GT:round OUT:reund\n",
            "32 GT:scene OUT:scone\n",
            "33 GT:score OUT:score\n",
            "34 GT:sense OUT:scnse\n",
            "35 GT:skill OUT:scill\n",
            "36 GT:sleep OUT:sceep\n",
            "37 GT:small OUT:scoll\n",
            "38 GT:storm OUT:scorm\n",
            "39 GT:table OUT:thbce\n",
            "40 GT:think OUT:think\n",
            "41 GT:touch OUT:thunh\n",
            "42 GT:twice OUT:thice\n",
            "43 GT:until OUT:unsil\n",
            "44 GT:upset OUT:unset\n",
            "45 GT:voice OUT:voice\n",
            "46 GT:waste OUT:wamce\n",
            "47 GT:watch OUT:wamch\n",
            "48 GT:white OUT:waite\n",
            "49 GT:woman OUT:waman\n",
            "50 GT:young OUT:young\n",
            "final text accuracy 50/50 (1.0000)\n",
            "whole text accuracy 155/200 (0.7750)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "chars = \"abcdefghijklmnopqrstuvwxyz\"\n",
        "char_list = [i for i in chars]\n",
        "n_letters = len(char_list)\n",
        "\n",
        "n_layers = 2\n",
        "\n",
        "five_words = ['basic','beach','below','black','brown','carry','cream','drink','error','event','exist','first','funny','guess','human','image','large','magic','mouse','night','noise','ocean','often','order','peace','phone','print','quiet','reach','rough','round','scene','score','sense','skill','sleep','small','storm','table','think','touch','twice','until','upset','voice','waste','watch','white','woman','young']\n",
        "n_five_words = len(five_words)\n",
        "\n",
        "sequence_length = 4\n",
        "\n",
        "def word_to_onehot(string):\n",
        "    one_hot = np.array([]).reshape(0,n_letters)\n",
        "    for i in string:\n",
        "        idx = char_list.index(i)\n",
        "        zero = np.zeros(shape=n_letters, dtype=int)\n",
        "        zero[idx] = 1\n",
        "        one_hot = np.vstack([one_hot, zero])\n",
        "    return one_hot\n",
        "\n",
        "def onehot_to_word(onehot_1):\n",
        "    onehot = torch.Tensor.numpy(onehot_1)\n",
        "    return char_list[onehot.argmax()]\n",
        "\n",
        "\n",
        "class myRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layer):\n",
        "        super(myRNN,  self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layer = num_layer\n",
        "        self.rnn = nn.RNN(input_size = input_size,hidden_size=hidden_size, num_layers=num_layer)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(self.num_layer, 1, self.hidden_size)\n",
        "\n",
        "\n",
        "def main():\n",
        "    n_hidden = 52\n",
        "    lr = 0.001\n",
        "    epochs = 900\n",
        "\n",
        "    model = myRNN(n_letters, n_hidden, n_layers)\n",
        "\n",
        "    loss_func = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 300, gamma=0.1)\n",
        "\n",
        "    for i in range(epochs):\n",
        "        total_loss = 0\n",
        "        for j in range(n_five_words):\n",
        "            hidden = model.init_hidden()\n",
        "            string = five_words[j]\n",
        "            one_hot = torch.from_numpy(word_to_onehot(string)).type_as(torch.FloatTensor())\n",
        "            model.zero_grad()\n",
        "            hidden = model.init_hidden()\n",
        "            input = one_hot[0:-1]\n",
        "            input = torch.unsqueeze(input, 1)\n",
        "            target = np.argmax(one_hot[1:], axis=1)\n",
        "\n",
        "            output, hidden  = model(input, hidden)\n",
        "            loss = loss_func(output.squeeze(1), target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "        if i%10 == 0:\n",
        "             print('epoch%d'%i)\n",
        "             print(loss)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    torch.save(model.state_dict(), 'trained.pth')\n",
        "    model.load_state_dict(torch.load('trained.pth'))\n",
        "\n",
        "\t\n",
        "    with torch.no_grad():\n",
        "        total = 0\n",
        "        positive = 0\n",
        "        total_text = 0\n",
        "        positive_text = 0\n",
        "        for i in range(n_five_words):\n",
        "            string = five_words[i]\n",
        "            one_hot = torch.from_numpy(word_to_onehot(string)).type_as(torch.FloatTensor())\n",
        "            hidden = model.init_hidden()\n",
        "\n",
        "            input = one_hot[0:-1]\n",
        "            input = torch.unsqueeze(input, 1)\n",
        "            target = np.argmax(one_hot[1:], axis=1)\n",
        "            output, hidden = model(input, hidden)\n",
        "            output = output.squeeze()\n",
        "\n",
        "            output_string = string[0]\n",
        "            for j in range(output.size()[0]):\n",
        "                output_string += onehot_to_word(output[j].data)\n",
        "                total_text += 1\n",
        "                if string[j+1] == output_string[-1]:\n",
        "                    positive_text += 1\n",
        "\n",
        "            total += 1\n",
        "            if string[-1] == output_string[-1]:\n",
        "                positive += 1\n",
        "\n",
        "            print('%d GT:%s OUT:%s'%(i+1, string, output_string))\n",
        "\n",
        "        print('final text accuracy %d/%d (%.4f)'%(positive, total, positive/total))\n",
        "        print('whole text accuracy %d/%d (%.4f)' % (positive_text, total_text, positive_text / total_text))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOZ0GLgb+ROhqmjP5gGFIiL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}